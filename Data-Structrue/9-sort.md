# 排序

## 排序算法的评价指标

![image-20250305135536249](imgs\image-20250305135536249.png)

1. 时间复杂度
2. 空间复杂度
3. 算法稳定性（稳定的：关键字相同的元素在排序之后相对位置不变）

* 不能说稳定的算法一定比不稳定的好，有的情况下对于相同的关键字怎么排序没有要求，所以哪种算法更优，要视情况而定

## 排序算法的分类

![image-20250305135816452](imgs\image-20250305135816452.png)

* 内部排序：需要排序的数据可以直接全部放在内存中
  * 衡量算法优劣，**只需要考虑时间复杂度、空间复杂度**、（有时要考虑稳定性）
* 外部排序：需要排序的数据太多，内存放不下
  * 衡量算法优劣，需要考虑时间复杂度、空间复杂度、**读写磁盘的次数**、（有时要考虑稳定性）

![image-20250305140153298](imgs\image-20250305140153298.png)

## 1. 插入排序

### （1）直接插入排序

![image-20250305140454550](imgs\image-20250305140454550.png)

* 选择-插入
* 直接插入排序进行$n$趟后能保证前$n+1$个元素是有序的，但是每一趟排序都不能保证有一个元素到达最终的位置上

#### 算法实现

##### 直接插入排序

![image-20250305140736276](imgs\image-20250305140736276.png)

##### 直接插入排序（带哨兵）

![image-20250305140903784](imgs\image-20250305140903784.png)

#### 算法效率分析

![image-20250305141115305](imgs\image-20250305141115305.png)

### （2）折半插入排序

![image-20250305141512718](imgs\image-20250305141512718.png)

* 优化了插入的操作，因为前边的数据已经有序了，可以使用折半查找确定插入位置
* 为了确保算法稳定性，即使 A[mid] = key，也应该当作 A[mid] < key 进行下一步的查找
* 最后 high < low 时，[low, i - 1] 的所有元素向右移一位，key 放在 A[low] 位置

#### 算法实现、算法效率分析

![image-20250618220750934](imgs\image-20250618220750934.png)

* 为了保持稳定性，当 A[mid]==A[0] 时，也要让 low=mid+1

  最终可以保证 [low, i-1]都 ≥ 待排序元素

![image-20250305142045093](imgs\image-20250305142045093.png)

* 直接插入排序中，一共要进行 n-1 轮的排序，每轮都有 查找+插入 操作，最坏形况下是逆序，每轮都要查找 i 次，插入 i 次，所以最坏时间复杂度是 $O(n^2)$
* 折半插入排序中，还是要进行 n-1 轮的排序，每轮都有 查找+插入 操作，最坏情况下是逆序，每轮查找要 $log_2i$ 次，插入 i 次，所以最坏时间复杂度还是 $O(n^2)$

### 对链表进行插入排序

* 折半查找只适用于 有序的顺序表，所以对链表进行插入排序，只能用直接插入排序

![image-20250305142657147](imgs\image-20250305142657147.png)

* 对链表的直接插入排序中，一共要进行 n-1 轮的排序，每轮都有 查找+插入 操作，最坏形况下是逆序，每轮都要查找 i 次，插入 1 次，所以最坏时间复杂度还是 $O(n^2)$

### 插入排序总结

![image-20250305142910878](imgs\image-20250305142910878.png)

## 2. 希尔排序

* 对于直接插入排序，如果关键字基本有序，则排序效率会高
* 希尔排序是直接插入排序的优化，先基本有序，然后全局有序

![image-20250618221936835](imgs\image-20250618221936835.png)

![image-20250618222150805](imgs\image-20250618222150805.png)

* 希尔排序的增量d，是指把待排序表分成了**d个子表**，分别对这d个子表进行排序
  * 第1个子表，元素下标包含 1, 1+d, 1+2d ...（默认下标0所在位置没有元素）
  * 第1个子表，元素下标包含 2, 2+d, 2+2d ...（默认下标0所在位置没有元素）
  * ......
  * 第d个子表，元素下标包含 d, d+2d, d+3d ...（默认下标0所在位置没有元素）

![image-20250305153640560](imgs\image-20250305153640560.png)

* 根据增量确定子表，对子表进行直接插入排序

### 算法实现

![image-20250305154216660](imgs\image-20250305154216660.png)

### 算法效率分析

![image-20250305154330663](imgs\image-20250305154330663.png)

* 最坏情况下，第一次选的增量就是1，退化成直接插入排序，时间复杂度是 $O(n^2)$ 

![image-20250305154456582](imgs\image-20250305154456582.png)

* 希尔排序是不稳定排序
* 希尔排序需要根据增量选子表，所以只适用于顺序表

### 希尔排序总结

![image-20250305154606620](imgs\image-20250305154606620.png)

+ 希尔排序在最后一趟前都不能保证元素在最后的位置上。
+ 希尔排序在最后一趟前都不能保证元素是有序的。

## 3. 交换排序

* 每一趟排序都会确保由一个元素到达最终的位置

### （1）冒泡排序

![image-20250305155114881](imgs\image-20250305155114881.png)

* 从后往前，两两比较，每次都能确定一个最终位置
* 每一轮判断时，对于前边已经确定最终位置的元素，不需要再进行比较了
* 如果某一趟没有发生交换，说明此时已经整体有序，排序提前结束

##### 算法实现

![image-20250305155552916](imgs\image-20250305155552916.png)

* 冒泡排序是稳定排序

##### 算法效率分析

![image-20250305155742262](imgs\image-20250305155742262.png)

* 冒泡排序的时间复杂度是由 对比的次数 + 交换的次数 决定的
* 平均时间复杂度 $O(n^2)$
* 交换的次数（即swap()函数执行的次数），而移动元素的次数 = 3 * 交换的次数

#### 对链表进行冒泡排序

![image-20250305160011639](imgs\image-20250305160011639.png)

* 冒泡排序可以用于链表

#### 冒泡排序总结

![image-20250305160108888](imgs\image-20250305160108888.png)

### （2）快速排序

![image-20250305160737937](imgs\image-20250305160737937.png)

![image-20250305160755191](imgs\image-20250305160755191.png)

<img src="imgs\image-20250305161040704.png" alt="image-20250305161040704" style="zoom:50%;" />

* 每次都可以确定 选取的枢纽元素 的最终位置
* 枢纽元素 确定后，把原本的排序表划分成两部分，再对这两部分分别进行快速排序，一直划分到排序表里只有 0 或 1 个元素

##### 算法实现

![image-20250305170141822](imgs\image-20250305170141822.png)

##### 算法效率分析

![image-20250305171144995](imgs\image-20250305171144995.png)

![image-20250305171132618](imgs\image-20250305171132618.png)

![image-20250305171203341](imgs\image-20250305171203341.png)

* 每次递归，时间 主要花费在 遍历所有当前 low - high  的元素上，而每一层递归遍历的元素个数是逐渐减小的，并且都 < n

* 时间复杂度：$O(递归层数 * n)$

* 空间复杂度：$O(递归层数)$

* 快速排序的每次枢纽把排序表划分成两个子表，可以幻视成划分子树。递归层数就是排序表最终的树高

* 已知有 n 个关键字（结点），则树高最高是 n，最低是 $\lfloor log_2n \rfloor + 1$

* 即 时间复杂度：$O(nlog_2n) - O(n^2)$

  空间复杂度：$O(log_2n) - O(n)$

![image-20250305170530245](imgs\image-20250305170530245.png)

* **如果初始序列是 有序 或 逆序 的，快速排序性能最差**

###### 优化思路

![image-20250305171919657](imgs\image-20250305171919657.png)

* 快速排序在初始序列有序或逆序时效率最差，所以主要的优化思路就是每次尽可能选中间元素
  * 每次选low, high, mid里的中间值
  * 每次随机选取

![image-20250305172115004](imgs\image-20250305172115004.png)

* 快速排序的平均时间复杂度是 $O(nlog_2n)$

<img src="imgs\image-20250305172248699.png" alt="image-20250305172248699" style="zoom:50%;" />

* 快速排序是不稳定排序

##### 快速排序总结

![image-20250305172503469](imgs\image-20250305172503469.png)

* 算法表现主要取决于 递归深度，递归深度主要取决于 划分均匀程度
* 408里的“一趟”指的是一层，所以一趟快速排序可能会确定多个关键字的最终位置

## 4. 选择排序

* 每一趟在待排序元素中选取关键字最小或最大的元素加入有序子序列
* 选择排序执行的时间复杂度，与初始序列状态无关

### （1）简单选择排序

<img src="imgs\image-20250305161532313.png" alt="image-20250305161532313" style="zoom: 50%;" />

<img src="imgs\image-20250305161556552.png" alt="image-20250305161556552" style="zoom:50%;" />

* 每一趟在待排序元素中选取关键字最小的元素加入有序子序列
* 如果有最小关键字由多个，把先扫描到的先加入有序子序列（即使如此，但它是不稳定排序）
* 有 n 个元素的排序表，只需要进行 n-1 趟的处理（最后一次只有一个元素，不需要再找最小关键字了）

##### 算法实现

![image-20250305161909006](imgs\image-20250305161909006.png)

##### 算法效率分析

![image-20250305161958794](imgs\image-20250305161958794.png)

* 不管有序无序，都要进行 n-1 趟排序，每一趟的时间组成主要在 对比（每次都必须n-i-1次） + 交换（每次0或1次） 上

![image-20250305162444520](imgs\image-20250305162444520.png)

* 简单选择排序是不稳定排序
* 简单选择排序 适用于 顺序表 和 链表

##### 简单选择排序总结

![image-20250305162550213](imgs\image-20250305162550213.png)

#### 直接插入排序 简单选择排序

插入排序和选择排序都是分为未排序和已排序两个部分，那么其中有什么区别？

如$18$、$23$、$19$、$9$、$23*$、$15$进行排序。

18 23 19 9 23* 15

插入排序：

```txt
18 23 19 9 23* 15
18 19 23 9 23* 15
9 18 19 23 23* 15
9 18 19 23 23* 15
9 15 18 19 23 23*
```

选择排序：

```txt
9 23 19 18 23* 15
9 15 19 18 23* 23
9 15 18 19 23* 23
9 15 18 19 23* 23
9 15 18 19 23* 23
9 15 18 19 23* 23
```

### （2）堆排序

![image-20250305203610010](imgs\image-20250305203610010.png)

##### 大根堆、小根堆

![image-20250305203719324](imgs\image-20250305203719324.png)

##### 建立大根堆

![image-20250305204207986](imgs\image-20250305204207986.png)

* 从最后一个非终端结点（$\lfloor n/2 \rfloor$）从后往前依此判定每个结点是否满足大根堆，如果不满足，就让该结点和它孩子结点中的较大值交换。持续该操作到根节点
* 如果交换破坏了下一级的堆，就采用相同的方式继续向下调整（小元素不断下坠）

###### 建立大根堆的算法实现

![image-20250305205036273](imgs\image-20250305205036273.png)

##### 基于堆进行排序的原理

![image-20250305205159574](imgs\image-20250305205159574.png)

* 经过 n-1 趟处理之后，基于大根堆的堆排序，就能得到递增序列

![image-20250305205532202](imgs\image-20250305205532202.png)

##### 算法实现

![image-20250305205653029](imgs\image-20250305205653029.png)

##### 算法效率分析

![image-20250305210033138](imgs\image-20250305210033138.png)

![image-20250305210225727](imgs\image-20250305210225727.png)

* 堆排序的时间主要花费在  建堆 + 交换调整
* 建堆的时间复杂度是 $O(n)$
* 交换调整一共要进行 n-1 趟，每次最多下坠 h-1 次，每次下坠对比关键字最多 2 次（也就是说，每次交换调整的时间复杂度 < $2 * (h-1) = 2 * (\lfloor log_2n \rfloor + 1 - 1)$，时间复杂度是 $O(log_2n)$。所以交换调整总花费时间复杂度是 $O(nlog_2n)$
* 堆排序的时间复杂度 = $O(nlog_2n)$
* 堆排序的空间复杂度 = $O(1)$

![image-20250305210923795](imgs\image-20250305210923795.png)

![image-20250305211026076](imgs\image-20250305211026076.png)

* 堆排序是不稳定排序

##### 堆排序总结

![image-20250305211206509](imgs\image-20250305211206509.png)

#### 堆的插入删除

##### 插入

![image-20250305212153231](imgs\image-20250305212153231.png)

![image-20250305212356796](imgs\image-20250305212356796.png)

* 上升时，只需要和父结点进行对比，所以一次上升是对比一次的

##### 删除

![image-20250305212303687](imgs\image-20250305212303687.png)

![image-20250305212333460](imgs\image-20250305212333460.png)

* 下降时，两个孩子结点对比一次（如果没有两个孩子结点，则不必进行这次比较），根据是大根堆/小根堆，父结点和较大/较小的元素对比一次，所以一次下坠是对比两次/一次的

![image-20250305212751241](imgs\image-20250305212751241.png)

##### 堆的总结

![image-20250305212921778](imgs\image-20250305212921778.png)

+ 堆排序适合关键字较多的情况。创如，在$1$亿个数中选出前$100$个最大值，首先使用一个大小为$100$的数组，读入前$100$个数，建立小顶堆，而后依次读入余下的教，若小于堆顶则舍弃，否则用该数取代堆顶并重新调整堆，待数据读取完毕，堆中$100$个数即为所求。
+ 在含有$n$个关键字的小根堆中，关键字最大的记录存储范围为$\lfloor\dfrac{n}{2}\rfloor+1\sim n$。这是小根堆，关键字最大的记录一定存储在这个堆所对应的完全二叉树的叶子结点中；又因为二叉树中的最后一个非叶子结点存储在$\lfloor\dfrac{n}{2}\rfloor$中，所以得到范围。

## 5. 归并排序

![image-20250305172943145](imgs\image-20250305172943145.png)

* 归并：把两个原本有序的序列合并成一个有序序列

![image-20250305173303900](imgs\image-20250305173303900.png)

* 刚开始默认每个元素是一个序列
* 归并 2 个有序序列，叫做 2 路归并，每选出一个最小元素只需要进行 1 次比较
* 归并 n 个有序序列，叫做 n 路归并，每选出一个最小元素需要进行 n-1 次比较
* 归并的路数越多，每次选择最小元素需要对比关键字的个数也越多

![image-20250305173431320](imgs\image-20250305173431320.png)

* 内部排序的归并排序一般都使用 2路归并

#### 算法实现

![image-20250305174010263](imgs\image-20250305174010263.png)

* 归并排序使用了递归算法

#### 算法效率分析

![image-20250305174303345](imgs\image-20250305174303345.png)

* 归并趟数 = 归并树高 - 1
* 每一趟主要时间花费在遍历需要进行归并的数组上，每一趟都不会遍历超过n次。
* 总体时间复杂度：$O(nlog_2n)$
* 空间复杂度 = 递归调用栈($O(log_2n)$) + 辅助数组($O(n)$) = $O(n)$
* 归并排序是稳定排序

#### 归并排序总结

![image-20250305174748196](imgs\image-20250305174748196.png)

## 6. 基数排序

![image-20250305175524521](imgs\image-20250305175524521.png)

![image-20250305175439817](imgs\image-20250305175439817.png)

* 基数排序不是基于比较的排序算法
* 只能对整数进行排序
* 元素的移动次数与关键字的初始排列次序无关

#### 算法效率分析

![image-20250305180216570](imgs\image-20250305180216570.png)

* 基数排序通常基于链式存储实现（建立 r 个辅助队列的空间复杂度、收集操作的时间复杂度会比较低）
* r 是基数的位数（比如是十进制数，那 r = 10）
* d 是关键字的位数（比如关键字有 个十百，那 d = 3）

![image-20250305180334546](imgs\image-20250305180334546.png)

* 基数排序是稳定排序

#### 基数排序的应用

![image-20250305180739421](imgs\image-20250305180739421.png)

* 如果要从小到大排序，就让辅助队列的基数从小到大排即可
* 分配的 d 也不一定是个十百这种，只要划分有意义就可
* 可以看出，有时基数排序的速度甚至快过 $O(nlog_2n)$（视情况而定，并不总是这样）

#### 基数排序的适用场景

![image-20250305181204742](imgs\image-20250305181204742.png)

* 适用于 r、d 较小，而 n 较大的场景

#### 基数排序总结

![image-20250305181639764](imgs\image-20250305181639764.png)

## 外部排序

### 外存与内存之间的数据交换

![image-20250305230814408](imgs\image-20250305230814408.png)

* 在外存，数据是以磁盘块为单位进行存储的
* 内存以“块”为单位读磁盘，然后在内存中进行修改，然后写回磁盘

### 外部排序的原理

![image-20250305231329631](imgs\image-20250305231329631.png)

![image-20250305231309477](imgs\image-20250305231309477.png)

* 构造初始归并段：每次都两个磁盘块读入两个输入缓冲区，经过内部排序使这两个磁盘块里的内容递增/递减，然后根据输出缓冲区，再依次把这两个磁盘块写回外存。
* 一共16个磁盘块，每个磁盘块都要读入一次，写出一次，所以这里有32次的访问外存操作
* 这样就构造了8个有序的初始归并段

![image-20250305231933399](imgs\image-20250305231933399.png)

* 接下来的操作就是归并排序，第一趟归并把8个归并段合并成4个归并段，第二趟变成2个，第三趟变成1个，归并结束

![image-20250305232209074](imgs\image-20250305232209074.png)

* 排过序的内容其实放在外存的其他空闲位置了，当前磁盘块内容会归还给系统

* 输入缓冲区1，输入缓冲区2，从始至终大小不变。

  输入缓冲区1专门放归并段1的内容，输入缓冲区2专门放归并段2的内容

  每当输入缓冲区空，应立即再从归并段拿下一个块存进输入缓冲区，保证总是归并段1的最小部分和归并段2的最小部分进行比较

### 算法效率分析

![image-20250305233323442](imgs\image-20250305233323442.png)

* 外部排序时间开销 = 读写外存的时间 + 内部排序时间 + 内部归并时间，其中读写外存最占时间
* 读写外存的次数 = 文件总块数（生成初始归并段） + 文件总块数 * 归并趟数（每次归并完重新写入外存）
* 优化外部排序的思路，就是想办法减少归并的趟数

### 优化1：多路归并

![image-20250305234842879](imgs\image-20250305234842879.png)

* 归并的趟数 = 归并树高 - 1

* 假设使用 k 路归并，求归并树的最低树高

  假设树高是 h，则 k 叉树的第 h 层最多有 $k^{h-1}$ 个结点，可知初始归并段 $ r ≤ K^{h-1}$

* 所以 $归并趟数 = h - 1 ≥ \lceil log_kr \rceil$，增大归并路数 k，或减小初始归并段数量 r，都可以减少归并趟数

* 多路归并的思路，是增大 k。但k不是越大越好的，k增大会增加内存空间开销，并且多路排序的路数过多，每次归并排序的比较次数 = k-1，也会增加，内部归并所需要的时间增加

### 优化2：减少初始归并段数量

![image-20250306113709109](imgs\image-20250306113709109.png)

* 增加生成初始归并段的内存工作区，生成更少的初始归并段

### 外部排序总结

![image-20250306113942867](imgs\image-20250306113942867.png)

* 增大 k，或者减小 r
* 但 k 不能无节制增大，k 增大也会增大内部归并的速度（用败者树可以解决这个问题）
* r = N/L，N是外存待排序的磁盘块数目，L是生成初始归并段时的内存工作区大小（用置换-选择排序可以进一步的让r更小）

### 多路平衡归并的定义

![image-20250306114722183](imgs\image-20250306114722183.png)

* 多路平衡归并，不是每次必须是k路归并段进行归并（比如说有2个归并段，根本构不成k路归并）
* 而是每次假如有m路要进行归并，必须生成 $\lceil m / k \rceil$ 个新归并段

## 败者树

![image-20250306120026765](imgs\image-20250306120026765.png)

* 多路平衡归并有 k 路，每次确定最小/最大关键字（取决于排序要求是从小到大还是从大到小）就要进行 k-1 次的比较
* 也就是说 k 越大，内部归并耗时越长
* 败者树优化这个问题

### 定义

![image-20250306120217820](imgs\image-20250306120217820.png)

* 打擂台，有 n 个参赛者，就打 n-1 次擂台，每次擂台后，结点记录失败者
* 最下方的 n 个参赛者是叶子结点

![image-20250306121042013](imgs\image-20250306121042013.png)

* 用败者树进行归并，非叶子结点存的都是**归并段的编号**，而这些叶子结点实际上是不进行存储的。
  * 也就是说，败者树是存储在一个长度为 k 的数组里的
* 除了最高层的顶点，败者树是完全二叉树
* 有的教材把最上方结点称为根结点，有的教材把第二层的结点称为根结点，但总之算树高的时候，是不带最高层结点那一层的
* 构建好败者树之后，最小/最大元素就在最上方的结点上，取下它（相当于在它所在的归并段选择当前指针指向的结点作为当前的最小/最大关键字，所以所在归并段的指针要后移一位，它指向的元素加入到败者树，进行新一轮的关键字比较
* 每次删除元素，加入新元素，只需要从叶子结点开始到根结点的路径上不断进行比对，胜利者进入下一轮的比赛，直到比出一个新的最高层结点（比较的次数 <= 树高h - 1 = $\lceil log_2k \rceil$，因为有可能是完全二叉树但不是满二叉树，也可能当前的关键字是从倒数第二层开始比较的）
* 也就是说，原本每次取得最小/最大关键字要进行关键字的对比 k-1 次，使用了败者树之后，除了第一次需要对比 k-1 次，之后都只需要对比 $\lceil log_2k \rceil$ 次

## 置换选择排序

* 在进行外部排序时，已知排序次数 =  h-1 = $\lceil log_kr \rceil$，所以为了减少排序次数，就增大 k， 或者减小 r
* 增大 k 造成的内部归并时间增加问题，被败者树优化了
* 减小 r 的方式就是增大初始归并时的内存工作区
  * 初始归并段的个数 r = N/初始归并段的大小（N是待排序的磁盘块数）
  * 当前，初始归并段的大小 = L （L是内存工作区大小）
  * 置换选择排序的作用，就是在内存工作区大小 L 不变的情况下，增大初始归并段的大小

### 定义

![image-20250306142009422](imgs\image-20250306142009422.png)

![image-20250306142432157](imgs\image-20250306142432157.png)

* 内存工作区有一个MINIMAX关键字，存储当前归并段的最大值

* 从内存工作区里挑最小值，如果这个值 > MINIMAX，则把这个值放到当前归并段末尾，MINIMAX的值更新

  如果这个值 < MINIMAX，把这个值标红，并当作内存归并段没有这个值，然后继续找最小值，合并到归并段

* 一直到内存工作区的内容全部标红，说明一个归并段结束

* 内存工作区的现有 MINIMAX 更新，开始下一个归并段

* 循环，一直到所有待排序磁盘块都已经排序

* 使用置换选择排序生成的**初始归并段，长度可能是各不相同的**

## 最佳归并树

![image-20250306142909880](imgs\image-20250306142909880.png)

* 经过置换选择排序，生成的初始归并段，长度互相不同
* 如果是 2 路归并，一次选长度为 5，1的两个初始归并段进行归并，它们的归并需要 读写内存各6次
* 最后外部排序结束时，总共需要访问外存的次数，就是 **归并树的带权路径长度 * 2（读一次，写一次）**
* 要让磁盘I/O次数最少，就要让归并树的WPL最小——**哈夫曼树**

### 定义

![image-20250306143347869](imgs\image-20250306143347869.png)

### 多路归并的最佳归并树

![image-20250306143555561](imgs\image-20250306143555561.png)

#### 多路归并可能遇到的问题

* 如果是2路归并，总能用哈夫曼树表示

* 但如果是 k 路归并，可能初始归并段的个数，并不是 k 的整数倍，即不能保证每次都是 k 路归并

  * 例如下边的 3 路归并，但初始归并段只有 8 个，那最后一次归并只能是 2 路归并，这可能不是最佳归并树

  ![image-20250306143925402](imgs\image-20250306143925402.png)

#### 添加虚段

![image-20250306144215776](imgs\image-20250306144215776.png)

* 补充几个长度为$0$的虚段，从而能保证严格$k$叉归并

![image-20250306144518100](imgs\image-20250306144518100.png)

* $n_0 + n_k = n$
* $k * n_k = n - 1$
* 所以 $n_k = \frac{n_0 - 1}{k - 1}$
* 如果 $\frac{n_0 - 1}{k - 1} = 0$，不需要补充虚段
* 如果 $\frac{n_0 - 1}{k - 1} = u ≠ 0$，需要补充 $k - 1 - u$ 个虚段（就是添加完虚段之后满足 $\frac{n_0 - 1}{k - 1} = 0$ ）

![image-20250306144557906](imgs\image-20250306144557906.png)



